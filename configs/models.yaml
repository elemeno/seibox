# Model configuration and cost table
# Pricing updated as of January 2025

default:
  name: "openai:gpt-4o-mini"
  temperature: 0.0
  max_tokens: 512

models:
  # ============================================
  # OpenAI GPT Models
  # ============================================
  
  # GPT-5 Family (Latest - August 2025)
  - name: "openai:gpt-5"
    cost:
      input_per_1k: 0.00125   # $1.25 per 1M tokens
      output_per_1k: 0.01     # $10.00 per 1M tokens
    context_length: 272000
    description: "Most advanced GPT-5 model with superior reasoning capabilities"
  
  - name: "openai:gpt-5-mini"
    cost:
      input_per_1k: 0.00025   # $0.25 per 1M tokens
      output_per_1k: 0.002    # $2.00 per 1M tokens
    context_length: 272000
    description: "Cost-effective GPT-5 mini variant"
  
  - name: "openai:gpt-5-nano"
    cost:
      input_per_1k: 0.00005   # $0.05 per 1M tokens
      output_per_1k: 0.0004   # $0.40 per 1M tokens
    context_length: 272000
    description: "Ultra-efficient GPT-5 nano model"
  
  # GPT-4.1 Family (Latest - 2024, 1M token context)
  - name: "openai:gpt-4.1"
    cost:
      input_per_1k: 0.03      # $30 per 1M tokens
      output_per_1k: 0.12     # $120 per 1M tokens
    context_length: 1000000
    description: "Latest GPT-4.1 with major improvements in coding and instruction following"
  
  - name: "openai:gpt-4.1-mini"
    cost:
      input_per_1k: 0.0015    # $1.50 per 1M tokens  
      output_per_1k: 0.006    # $6.00 per 1M tokens
    context_length: 1000000
    description: "Cost-effective GPT-4.1 variant with strong performance"
  
  - name: "openai:gpt-4.1-nano"
    cost:
      input_per_1k: 0.0004    # $0.40 per 1M tokens
      output_per_1k: 0.0016   # $1.60 per 1M tokens  
    context_length: 1000000
    description: "First nano model - ultra-efficient for simple tasks"
  
  # GPT-4o Family (Current production)
  - name: "openai:gpt-4o-mini"
    cost:
      input_per_1k: 0.00015  # $0.15 per 1M tokens
      output_per_1k: 0.0006   # $0.60 per 1M tokens
    context_length: 128000
    description: "Most cost-effective GPT-4o variant"
  
  - name: "openai:gpt-4o"
    cost:
      input_per_1k: 0.0025   # $2.50 per 1M tokens
      output_per_1k: 0.01     # $10.00 per 1M tokens
    context_length: 128000
    description: "Balanced performance and cost, multimodal capabilities"
  
  # GPT-4 Family (Legacy but still available)
  - name: "openai:gpt-4-turbo"
    cost:
      input_per_1k: 0.01      # $10 per 1M tokens
      output_per_1k: 0.03     # $30 per 1M tokens
    context_length: 128000
    description: "GPT-4 Turbo with vision capabilities"
  
  - name: "openai:gpt-4"
    cost:
      input_per_1k: 0.03      # $30 per 1M tokens
      output_per_1k: 0.06     # $60 per 1M tokens
    context_length: 8192
    description: "Original GPT-4 model"
  
  - name: "openai:gpt-4-0613"
    cost:
      input_per_1k: 0.03      # $30 per 1M tokens
      output_per_1k: 0.06     # $60 per 1M tokens
    context_length: 8192
    description: "GPT-4 June 2023 snapshot"
  
  # GPT-3.5 Family (Most economical)
  - name: "openai:gpt-3.5-turbo"
    cost:
      input_per_1k: 0.0005    # $0.50 per 1M tokens
      output_per_1k: 0.0015   # $1.50 per 1M tokens
    context_length: 16385
    description: "Latest GPT-3.5 Turbo model"
  
  - name: "openai:gpt-3.5-turbo-0125"
    cost:
      input_per_1k: 0.0005    # $0.50 per 1M tokens
      output_per_1k: 0.0015   # $1.50 per 1M tokens
    context_length: 16385
    description: "GPT-3.5 Turbo January 2024 snapshot"
  
  # ============================================
  # Anthropic Claude Models
  # ============================================
  
  # Claude 4.1 Family (Latest - August 2025)
  - name: "anthropic:claude-4-1-opus"
    cost:
      input_per_1k: 0.015     # $15 per 1M tokens
      output_per_1k: 0.075    # $75 per 1M tokens
    context_length: 200000
    description: "Most intelligent Claude model with hybrid reasoning and superior performance"
    prompt_caching:
      write: 0.01875  # $18.75 per 1M tokens
      read: 0.0015    # $1.50 per 1M tokens
  
  # Claude 4 Family (Latest - 2025)
  - name: "anthropic:claude-4-opus"
    cost:
      input_per_1k: 0.015     # $15 per 1M tokens
      output_per_1k: 0.075    # $75 per 1M tokens
    context_length: 200000
    description: "Most capable Claude 4 model, premium performance"
  
  - name: "anthropic:claude-4-sonnet"
    cost:
      input_per_1k: 0.003     # $3 per 1M tokens (≤200K tokens)
      output_per_1k: 0.015    # $15 per 1M tokens (≤200K tokens)
    context_length: 200000
    description: "Balanced Claude 4 model with tiered pricing for >200K tokens"
    note: "Higher rates apply for >200K tokens: $6 input / $22.50 output per 1M"
  
  # Claude 3.7 Family
  - name: "anthropic:claude-3-7-sonnet"
    cost:
      input_per_1k: 0.003     # $3 per 1M tokens
      output_per_1k: 0.015    # $15 per 1M tokens
    context_length: 200000
    description: "Enhanced Claude 3.7 Sonnet with improved capabilities"
  
  # Claude 3.5 Family (Updated pricing)
  - name: "anthropic:claude-3-5-sonnet-20241022"
    cost:
      input_per_1k: 0.003     # $3 per 1M tokens
      output_per_1k: 0.015    # $15 per 1M tokens
    context_length: 200000
    description: "Claude 3.5 Sonnet with advanced reasoning"
  
  - name: "anthropic:claude-3-5-haiku-20241022"
    cost:
      input_per_1k: 0.0008    # $0.80 per 1M tokens (updated pricing)
      output_per_1k: 0.004    # $4 per 1M tokens (updated pricing)
    context_length: 200000
    description: "Claude 3.5 Haiku with updated pricing reflecting increased intelligence"
  
  # Claude 3 Family (Original)
  - name: "anthropic:claude-3-opus-20240229"
    cost:
      input_per_1k: 0.015     # $15 per 1M tokens
      output_per_1k: 0.075    # $75 per 1M tokens
    context_length: 200000
    description: "Most capable Claude 3 model"
  
  - name: "anthropic:claude-3-sonnet-20240229"
    cost:
      input_per_1k: 0.003     # $3 per 1M tokens
      output_per_1k: 0.015    # $15 per 1M tokens
    context_length: 200000
    description: "Balanced Claude 3 model"
  
  - name: "anthropic:claude-3-haiku-20240307"
    cost:
      input_per_1k: 0.00025  # $0.25 per 1M tokens
      output_per_1k: 0.00125  # $1.25 per 1M tokens
    context_length: 200000
    description: "Fastest and most cost-effective Claude 3 model"
  
  # Legacy Models (for backward compatibility)
  - name: "anthropic:claude-instant-1.2"
    cost:
      input_per_1k: 0.0008    # $0.80 per 1M tokens
      output_per_1k: 0.0024   # $2.40 per 1M tokens
    context_length: 100000
    description: "Legacy Claude Instant model (if still available)"
  
  - name: "anthropic:claude-2.1"
    cost:
      input_per_1k: 0.008     # $8 per 1M tokens
      output_per_1k: 0.024    # $24 per 1M tokens
    context_length: 200000
    description: "Legacy Claude 2.1 model (if still available)"

  # ============================================
  # vLLM Local Models
  # ============================================
  
  # Popular open-source models for local deployment
  - name: "vllm:llama-2-7b"
    cost:
      input_per_1k: 0.0       # Free (local compute cost not tracked)
      output_per_1k: 0.0      # Free (local compute cost not tracked)
    context_length: 4096
    description: "Meta Llama 2 7B model via vLLM server"
  
  - name: "vllm:llama-2-13b"
    cost:
      input_per_1k: 0.0       # Free (local compute cost not tracked)
      output_per_1k: 0.0      # Free (local compute cost not tracked)
    context_length: 4096
    description: "Meta Llama 2 13B model via vLLM server"
  
  - name: "vllm:mistral-7b"
    cost:
      input_per_1k: 0.0       # Free (local compute cost not tracked)
      output_per_1k: 0.0      # Free (local compute cost not tracked)
    context_length: 8192
    description: "Mistral 7B model via vLLM server"
  
  - name: "vllm:codellama-7b"
    cost:
      input_per_1k: 0.0       # Free (local compute cost not tracked)
      output_per_1k: 0.0      # Free (local compute cost not tracked)
    context_length: 16384
    description: "CodeLlama 7B model via vLLM server"
  
  - name: "vllm:vicuna-7b"
    cost:
      input_per_1k: 0.0       # Free (local compute cost not tracked)
      output_per_1k: 0.0      # Free (local compute cost not tracked)
    context_length: 2048
    description: "Vicuna 7B model via vLLM server"

  # ============================================
  # Google Gemini Models
  # ============================================
  
  # Gemini 2.0 Family (Latest - December 2024)
  - name: "gemini:gemini-2.0-flash-001"
    cost:
      input_per_1k: 0.00005   # $0.05 per 1M tokens (free tier available)
      output_per_1k: 0.0002   # $0.20 per 1M tokens (free tier available)
    context_length: 1048576   # 1M token context
    description: "Latest Gemini 2.0 Flash model with fastest inference and multimodal capabilities"
    free_tier:
      rate_limit: "5 RPM, 25 requests/day"
      note: "Free tier available via Google AI Studio"
  
  # Gemini 1.5 Family (Production stable)
  - name: "gemini:gemini-1.5-pro"
    cost:
      input_per_1k: 0.00125   # $1.25 per 1M tokens (64% reduction from previous pricing)
      output_per_1k: 0.005    # $5.00 per 1M tokens (52% reduction from previous pricing)
    context_length: 2097152   # 2M token context
    description: "Most capable Gemini 1.5 model with large context window"
    rate_limits:
      free_tier: "2 RPM"
      paid_tier: "1000 RPM"
  
  - name: "gemini:gemini-1.5-flash"
    cost:
      input_per_1k: 0.000075  # $0.075 per 1M tokens
      output_per_1k: 0.0003   # $0.30 per 1M tokens
    context_length: 1048576   # 1M token context
    description: "Balanced Gemini 1.5 model optimized for speed and efficiency"
    rate_limits:
      free_tier: "15 RPM"
      paid_tier: "2000 RPM"
  
  - name: "gemini:gemini-1.5-flash-8b"
    cost:
      input_per_1k: 0.0000375 # $0.0375 per 1M tokens
      output_per_1k: 0.00015  # $0.15 per 1M tokens
    context_length: 1048576   # 1M token context  
    description: "Smaller, faster Gemini 1.5 Flash variant for high-volume use cases"
    rate_limits:
      free_tier: "15 RPM"
      paid_tier: "2000 RPM"
  
  # Gemini 1.0 Family (Legacy but stable)
  - name: "gemini:gemini-1.0-pro"
    cost:
      input_per_1k: 0.0005    # $0.50 per 1M tokens
      output_per_1k: 0.0015   # $1.50 per 1M tokens
    context_length: 32768     # 32K token context
    description: "Original Gemini Pro model with proven stability"
    rate_limits:
      free_tier: "60 RPM"
      paid_tier: "1000 RPM"